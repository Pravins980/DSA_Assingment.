{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "General Linear Model:\n",
    "\n",
    "1. What is the purpose of the General Linear Model (GLM)?\n",
    "2. What are the key assumptions of the General Linear Model?\n",
    "3. How do you interpret the coefficients in a GLM?\n",
    "4. What is the difference between a univariate and multivariate GLM?\n",
    "5. Explain the concept of interaction effects in a GLM.\n",
    "6. How do you handle categorical predictors in a GLM?\n",
    "7. What is the purpose of the design matrix in a GLM?\n",
    "8. How do you test the significance of predictors in a GLM?\n",
    "9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n",
    "10. Explain the concept of deviance in a GLM.\n",
    "\n",
    "Regression:\n",
    "\n",
    "11. What is regression analysis and what is its purpose?\n",
    "12. What is the difference between simple linear regression and multiple linear regression?\n",
    "13. How do you interpret the R-squared value in regression?\n",
    "14. What is the difference between correlation and regression?\n",
    "15. What is the difference between the coefficients and the intercept in regression?\n",
    "16. How do you handle outliers in regression analysis?\n",
    "17. What is the difference between ridge regression and ordinary least squares regression?\n",
    "18. What is heteroscedasticity in regression and how does it affect the model?\n",
    "19. How do you handle multicollinearity in regression analysis?\n",
    "20. What is polynomial regression and when is it used?\n",
    "\n",
    "Loss function:\n",
    "\n",
    "21. What is a loss function and what is its purpose in machine learning?\n",
    "22. What is the difference between a convex and non-convex loss function?\n",
    "23. What is mean squared error (MSE) and how is it calculated?\n",
    "24. What is mean absolute error (MAE) and how is it calculated?\n",
    "25. What is log loss (cross-entropy loss) and how is it calculated?\n",
    "26. How do you choose the appropriate loss function for a given problem?\n",
    "27. Explain the concept of regularization in the context of loss functions.\n",
    "28. What is Huber loss and how does it handle outliers?\n",
    "29. What is quantile loss and when is it used?\n",
    "30. What is the difference between squared loss and absolute loss?\n",
    "\n",
    "Optimizer (GD):\n",
    "\n",
    "31. What is an optimizer and what is its purpose in machine learning?\n",
    "32. What is Gradient Descent (GD) and how does it work?\n",
    "33. What are the different variations of Gradient Descent?\n",
    "34. What is the learning rate in GD and how do you choose an appropriate value?\n",
    "35. How does GD handle local optima in optimization problems?\n",
    "36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?\n",
    "37. Explain the concept of batch size in GD and its impact on training.\n",
    "38. What is the role of momentum in optimization algorithms?\n",
    "39. What is the difference between batch GD, mini-batch GD, and SGD?\n",
    "40. How does the learning rate affect the convergence of GD?\n",
    "\n",
    "Regularization:\n",
    "\n",
    "41. What is regularization and why is it used in machine learning?\n",
    "42. What is the difference between L1 and L2 regularization?\n",
    "43. Explain the concept of ridge regression and its role in regularization.\n",
    "44. What is the elastic net regularization and how does it combine L1 and L2 penalties?\n",
    "45. How does regularization help prevent overfitting in machine learning models?\n",
    "46. What is early stopping and how does it relate to regularization?\n",
    "47. Explain the concept of dropout regularization in neural networks.\n",
    "48. How do you choose the regularization parameter in a model?\n",
    "49. What\n",
    "\n",
    " is the difference between feature selection and regularization?\n",
    "50. What is the trade-off between bias and variance in regularized models?\n",
    "\n",
    "SVM:\n",
    "\n",
    "51. What is Support Vector Machines (SVM) and how does it work?\n",
    "52. How does the kernel trick work in SVM?\n",
    "53. What are support vectors in SVM and why are they important?\n",
    "54. Explain the concept of the margin in SVM and its impact on model performance.\n",
    "55. How do you handle unbalanced datasets in SVM?\n",
    "56. What is the difference between linear SVM and non-linear SVM?\n",
    "57. What is the role of C-parameter in SVM and how does it affect the decision boundary?\n",
    "58. Explain the concept of slack variables in SVM.\n",
    "59. What is the difference between hard margin and soft margin in SVM?\n",
    "60. How do you interpret the coefficients in an SVM model?\n",
    "\n",
    "Decision Trees:\n",
    "\n",
    "61. What is a decision tree and how does it work?\n",
    "62. How do you make splits in a decision tree?\n",
    "63. What are impurity measures (e.g., Gini index, entropy) and how are they used in decision trees?\n",
    "64. Explain the concept of information gain in decision trees.\n",
    "65. How do you handle missing values in decision trees?\n",
    "66. What is pruning in decision trees and why is it important?\n",
    "67. What is the difference between a classification tree and a regression tree?\n",
    "68. How do you interpret the decision boundaries in a decision tree?\n",
    "69. What is the role of feature importance in decision trees?\n",
    "70. What are ensemble techniques and how are they related to decision trees?\n",
    "\n",
    "Ensemble Techniques:\n",
    "\n",
    "71. What are ensemble techniques in machine learning?\n",
    "72. What is bagging and how is it used in ensemble learning?\n",
    "73. Explain the concept of bootstrapping in bagging.\n",
    "74. What is boosting and how does it work?\n",
    "75. What is the difference between AdaBoost and Gradient Boosting?\n",
    "76. What is the purpose of random forests in ensemble learning?\n",
    "77. How do random forests handle feature importance?\n",
    "78. What is stacking in ensemble learning and how does it work?\n",
    "79. What are the advantages and disadvantages of ensemble techniques?\n",
    "80. How do you choose the optimal number of models in an ensemble?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9edf76",
   "metadata": {},
   "source": [
    "# General Linear Model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44749a28",
   "metadata": {},
   "source": [
    "1. What is the purpose of the General Linear Model (GLM)?\n",
    "\n",
    "ANS=The purpose of the General Linear Model (GLM) is to analyze the relationship between a dependent variable and one or more independent variables, and to estimate the effects of these variables on the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1dd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e225f063",
   "metadata": {},
   "source": [
    "2. What are the key assumptions of the General Linear Model?\n",
    "\n",
    "Ans=The key assumptions of the General Linear Model include linearity, independence of errors, homoscedasticity (constant variance of errors), normality of errors, and absence of multicollinearity among independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75346940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2fa590b",
   "metadata": {},
   "source": [
    "3. How do you interpret the coefficients in a GLM?\n",
    "\n",
    "ANs=In a GLM, coefficients represent the estimated effect of an independent variable on the dependent variable. They indicate the change in the dependent variable associated with a one-unit change in the independent variable, while holding other variables constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c3521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d89c682",
   "metadata": {},
   "source": [
    "4. What is the difference between a univariate and multivariate GLM?\n",
    "\n",
    "ANS=Univariate GLM involves analyzing the relationship between a single dependent variable and one independent variable. Multivariate GLM analyzes the relationship between a single dependent variable and multiple independent variables simultaneously\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55f1fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5ba830f",
   "metadata": {},
   "source": [
    "5. Explain the concept of interaction effects in a GLM.\n",
    "\n",
    "Interaction effects in a GLM occur when the relationship between an independent variable and the dependent variable varies based on the values of another independent variable. It means that the effect of one variable depends on the levels of another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204cb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc66e455",
   "metadata": {},
   "source": [
    "6. How do you handle categorical predictors in a GLM?\n",
    "\n",
    "Ans=Categorical predictors in a GLM are typically encoded as dummy variables, with each category represented by a separate binary variable. These variables are then included in the GLM as independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6a469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c91d19e",
   "metadata": {},
   "source": [
    "7. What is the purpose of the design matrix in a GLM?\n",
    "\n",
    "Ans=The design matrix in a GLM is a matrix representation of the independent variables used in the model. It organizes the predictor variables and their interactions, enabling the model to estimate the coefficients for each variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15ced4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06cdff8d",
   "metadata": {},
   "source": [
    "8. How do you test the significance of predictors in a GLM?\n",
    "\n",
    "ANS=The significance of predictors in a GLM is typically tested using hypothesis tests, such as t-tests or F-tests. These tests compare the estimated coefficients to their standard errors to determine if they are statistically different from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe527f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a7ed9c1",
   "metadata": {},
   "source": [
    "9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n",
    "\n",
    "ANs=Type I, Type II, and Type III sums of squares refer to different methods of partitioning the sum of squares in a GLM to test the significance of predictors. Type I sums of squares test the unique contribution of each variable, Type II sums of squares test the contribution after controlling for other variables, and Type III sums of squares test the contribution when all variables are included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8124f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ac0c5a",
   "metadata": {},
   "source": [
    "10. Explain the concept of deviance in a GLM.\n",
    "\n",
    "ANs=Deviance in a GLM measures the lack of fit between the observed data and the model's predictions. It is analogous to the residual sum of squares in ordinary least squares regression and is used to assess the goodness of fit of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d84779",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060558a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4e2a938",
   "metadata": {},
   "source": [
    "11. What is regression analysis and what is its purpose?\n",
    "\n",
    "ANs=Regression analysis is a statistical technique used to model the relationship between a dependent variable and one or more independent variables. Its purpose is to understand how changes in the independent variables are associated with changes in the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834cd35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3dd87f4",
   "metadata": {},
   "source": [
    "12. What is the difference between simple linear regression and multiple linear regression?\n",
    "\n",
    "Ans=Simple linear regression involves modeling the relationship between a dependent variable and a single independent variable. Multiple linear regression involves modeling the relationship between a dependent variable and multiple independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea330c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e35f93ad",
   "metadata": {},
   "source": [
    "13. How do you interpret the R-squared value in regression?\n",
    "\n",
    "Ans=The R-squared value in regression represents the proportion of the variance in the dependent variable that is explained by the independent variables. It ranges from 0 to 1, where 0 indicates no linear relationship and 1 indicates a perfect fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b231733b",
   "metadata": {},
   "source": [
    "14. What is the difference between correlation and regression?\n",
    "\n",
    "Ans=Correlation measures the strength and direction of the linear relationship between two variables, while regression analyzes the relationship between a dependent variable and one or more independent variables, allowing for prediction and estimation of effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b752c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8feac75e",
   "metadata": {},
   "source": [
    "15. What is the difference between the coefficients and the intercept in regression?\n",
    "\n",
    "ANs=Coefficients in regression represent the estimated effect of an independent variable on the dependent variable. The intercept represents the value of the dependent variable when all independent variables are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c816849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ed491f3",
   "metadata": {},
   "source": [
    "16. How do you handle outliers in regression analysis?\n",
    "\n",
    "Ans=Outliers in regression analysis can be handled by identifying and assessing their impact on the model. Options include removing the outliers, transforming the data, using robust regression techniques, or incorporating outlier-resistant models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11153b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7bdb612",
   "metadata": {},
   "source": [
    "17. What is the difference between ridge regression and ordinary least squares regression?\n",
    "\n",
    "Ans=Ordinary least squares (OLS) regression minimizes the sum of squared residuals, while ridge regression introduces a penalty term to the objective function to shrink the coefficient estimates towards zero, reducing their variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5cff80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1a8f211",
   "metadata": {},
   "source": [
    "18. What is heteroscedasticity in regression and how does it affect the model?\n",
    "\n",
    "ANs=Heteroscedasticity in regression occurs when the variance of the errors is not constant across all levels of the independent variables. It can affect the accuracy of coefficient estimates and hypothesis tests. Methods to handle heteroscedasticity include robust standard errors or transforming the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae12c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1abb3f76",
   "metadata": {},
   "source": [
    "19. How do you handle multicollinearity in regression analysis?\n",
    "\n",
    "Ans=Multicollinearity in regression refers to high correlation between independent variables, which can cause instability and imprecision in coefficient estimates. It can be addressed by removing redundant variables, combining variables, or using regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d351b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "348fa9e2",
   "metadata": {},
   "source": [
    "20. What is polynomial regression and when is it used\n",
    "\n",
    "Ans=Polynomial regression is a form of regression analysis where the relationship between the dependent variable and the independent variable(s) is modeled as an nth degree polynomial. It is used when the relationship is not linear and has curved patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf29af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e762a43",
   "metadata": {},
   "source": [
    "# Loss function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ce55b",
   "metadata": {},
   "source": [
    "21. What is a loss function and what is its purpose in machine learning?\n",
    "\n",
    "A loss function measures the discrepancy between predicted and actual values in machine learning. Its purpose is to quantify the error of a model and guide the optimization process to minimize this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ec4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8195922e",
   "metadata": {},
   "source": [
    "22. What is the difference between a convex and non-convex loss function?\n",
    "\n",
    "Mean squared error (MSE) is a loss function commonly used in regression tasks. It calculates the average squared difference between predicted and actual values, providing a measure of the model's accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f0b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "035327a1",
   "metadata": {},
   "source": [
    "23. What is mean squared error (MSE) and how is it calculated?\n",
    "\n",
    "Mean absolute error (MAE) is a loss function that calculates the average absolute difference between predicted and actual values. It is less sensitive to outliers compared to MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef802b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc070b8",
   "metadata": {},
   "source": [
    "24. What is mean absolute error (MAE) and how is it calculated?\n",
    "\n",
    "Mean absolute error (MAE) is a loss function that calculates the average absolute difference between predicted and actual values. It is less sensitive to outliers compared to MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cbfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13bbc51d",
   "metadata": {},
   "source": [
    "25. What is log loss (cross-entropy loss) and how is it calculated?\n",
    "\n",
    "Log loss, also known as cross-entropy loss, is a loss function used in classification tasks, particularly in logistic regression. It quantifies the difference between predicted and actual class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d9e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "904d1143",
   "metadata": {},
   "source": [
    "26. How do you choose the appropriate loss function for a given problem?\n",
    "\n",
    "The appropriate loss function depends on the problem and the desired properties of the model. MSE is commonly used for regression, while log loss is used for binary classification. The choice considers factors such as interpretability, robustness to outliers, and the specific problem domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631b421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5de258",
   "metadata": {},
   "source": [
    "27. Explain the concept of regularization in the context of loss functions.\n",
    "\n",
    "Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. It helps to simplify the model and reduce the impact of noisy or irrelevant features, improving generalization performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ddace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4be01e64",
   "metadata": {},
   "source": [
    "29. What is quantile loss and when is it used?\n",
    "\n",
    "Quantile loss is a loss function used for quantile regression, where the goal is to estimate conditional quantiles of the dependent variable. It measures the deviation between predicted and actual quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a77323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6abee085",
   "metadata": {},
   "source": [
    "28. What is Huber loss and how does it handle outliers?\n",
    "\n",
    "Huber loss is a loss function that combines squared loss for small errors and absolute loss for large errors. It is less sensitive to outliers compared to squared loss and less influenced by small errors compared to absolute loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f50d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c679d51f",
   "metadata": {},
   "source": [
    "30. What is the difference between squared loss and absolute loss?\n",
    "\n",
    "Squared loss (MSE) penalizes larger errors more heavily, while absolute loss (MAE) treats all errors equally. Squared loss is more sensitive to outliers, while absolute loss is less sensitive but lacks certain mathematical properties like differentiability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0a258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78902554",
   "metadata": {},
   "source": [
    "# Optimizer (GD):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bde58b",
   "metadata": {},
   "source": [
    "31. What is an optimizer and what is its purpose in machine learning?\n",
    "\n",
    "An optimizer is an algorithm or method used to adjust the parameters of a machine learning model to minimize the loss function. Its purpose is to find the optimal values that yield the best model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4feb9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04f43790",
   "metadata": {},
   "source": [
    "32. What is Gradient Descent (GD) and how does it work?Gradient Descent (GD) is an optimization algorithm that iteratively updates the model parameters in the direction of the steepest descent of the loss function. It involves computing gradients to determine the step size and direction\n",
    "\n",
    "Gradient Descent (GD) is an optimization algorithm that iteratively updates the model parameters in the direction of the steepest descent of the loss function. It involves computing gradients to determine the step size and direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41903ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cedc6f11",
   "metadata": {},
   "source": [
    "33. What are the different variations of Gradient Descent?\n",
    "\n",
    "Different variations of Gradient Descent include batch GD, mini-batch GD, and stochastic GD. Batch GD updates the parameters using the entire training dataset, while mini-batch GD and stochastic GD use subsets or individual samples, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5562cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054845b3",
   "metadata": {},
   "source": [
    "34. What is the learning rate in GD and how do you choose an appropriate value?\n",
    "The learning rate in GD controls the step size taken in each parameter update. Choosing an appropriate learning rate is important to ensure convergence. It should be small enough to avoid overshooting the minimum but large enough for efficient convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852c1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b740be9",
   "metadata": {},
   "source": [
    "35. How does GD handle local optima in optimization problems?\n",
    "\n",
    "GD can handle local optima by using gradient information to search for the minimum. However, it can still get stuck in suboptimal solutions if the loss function is highly non-convex. Techniques like random initialization and momentum can help escape local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508697aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecd6815e",
   "metadata": {},
   "source": [
    "36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is a variation of GD that updates the parameters using a single sample at a time. It can be faster than batch GD but introduces more noise due to the high variance in the estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f8215",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d28c41f9",
   "metadata": {},
   "source": [
    "37. Explain the concept of batch size in GD and its impact on training.\n",
    "\n",
    "Batch size in GD refers to the number of training samples used in each parameter update. Larger batch sizes provide smoother updates but require more memory, while smaller batch sizes introduce more noise but require less memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8b44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c4d5b2",
   "metadata": {},
   "source": [
    "38. What is the role of momentum in optimization algorithms?\n",
    "\n",
    "Momentum in optimization algorithms is a technique that introduces a velocity term to GD updates. It helps accelerate convergence by incorporating information from previous parameter updates, allowing for faster movement towards the minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615b0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "079604cd",
   "metadata": {},
   "source": [
    "39. What is the difference between batch GD, mini-batch GD, and SGD?\n",
    "\n",
    "Batch GD uses the entire training dataset for parameter updates, mini-batch GD uses subsets of the data, and SGD uses individual samples. Batch GD provides accurate parameter estimates but can be computationally expensive, while SGD offers faster updates but higher variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c565b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02acabb3",
   "metadata": {},
   "source": [
    "40. How does the learning rate affect the convergence of GD?\n",
    "\n",
    "\n",
    "The learning rate affects the convergence of GD. A learning rate that is too large can lead to overshooting and unstable updates, while a learning rate that is too small can cause slow convergence or getting stuck in local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8328f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
